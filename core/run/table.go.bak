package run

import (
	"bytes"
	"fmt"
	"golang.org/x/crypto/ssh"
	"io"
	"os"
	"os/exec"
	"strings"
	"sync"
	// "context"
	// "time"
	// "golang.org/x/sync/errgroup"

	"github.com/alajmo/sake/core"
	"github.com/alajmo/sake/core/dao"
)

func (run *Run) Table(dryRun bool) (dao.TableOutput, error) {
	task := run.Task
	servers := run.Servers

	var data dao.TableOutput
	var dataExit dao.TableOutput
	var dataMutex = sync.RWMutex{}

	/**
	 ** Headers
	 **/
	data.Headers = append(data.Headers, "server")
	dataExit.Headers = append(dataExit.Headers, "server")

	// Append Command names if set
	for _, subTask := range task.Tasks {
		data.Headers = append(data.Headers, subTask.Name)
		dataExit.Headers = append(dataExit.Headers, subTask.Name)
	}

	// Populate the rows (server name is first cell, then commands and cmd output is set to empty string)
	for i, p := range servers {
		data.Rows = append(data.Rows, dao.Row{Columns: []string{p.Name}})
		dataExit.Rows = append(dataExit.Rows, dao.Row{Columns: []string{p.Name}})

		for range task.Tasks {
			data.Rows[i].Columns = append(data.Rows[i].Columns, "")
			dataExit.Rows[i].Columns = append(dataExit.Rows[i].Columns, "")
		}
	}

	/**
	 ** Values
	 **/

	var wg sync.WaitGroup
	waitChan := make(chan struct{}, 100)
	for i := range servers {
		wg.Add(1)
		waitChan <- struct{}{}

		if task.Spec.Parallel {
			go func(i int, wg *sync.WaitGroup) {
				defer wg.Done()
				// TODO: Handle errors when running tasks in parallel
				_ = run.TableWork(i, dryRun, data, dataExit, &dataMutex)
				<-waitChan
			}(i, &wg)
		} else {
			err := func(i int, wg *sync.WaitGroup) error {
				defer wg.Done()
				err := run.TableWork(i, dryRun, data, dataExit, &dataMutex)

				return err
			}(i, &wg)

			if err != nil && run.Task.Spec.AnyErrorsFatal {
				// Return proper exit code for failed tasks
				switch err := err.(type) {
				case *ssh.ExitError:
					return data, &core.ExecError{Err: err, ExitCode: err.ExitStatus()}
				case *exec.ExitError:
					return data, &core.ExecError{Err: err, ExitCode: err.ExitCode()}
				default:
					return data, err
				}
			}
		}
	}

	wg.Wait()

	return data, nil
}

func (run *Run) TableWork(
	rIndex int,
	dryRun bool,
	data dao.TableOutput,
	dataExit dao.TableOutput,
	dataMutex *sync.RWMutex,
) error {
	config := run.Config
	task := run.Task
	server := run.Servers[rIndex]
	var wg sync.WaitGroup

	register := make(map[string]string)
	var registerEnvs []string
	for j, cmd := range task.Tasks {
		combinedEnvs := dao.MergeEnvs(cmd.Envs, server.Envs, registerEnvs)
		var client Client
		if cmd.Local || server.Local {
			client = run.LocalClients[server.Name]
		} else {
			client = run.RemoteClients[server.Name]
		}

		shell := dao.SelectFirstNonEmpty(cmd.Shell, server.Shell, config.Shell)
		shell = core.FormatShell(shell)
		workDir := getWorkDir(cmd, server)
		t := TaskContext{
			rIndex:  rIndex,
			cIndex:  j + 1,
			client:  client,
			dryRun:  dryRun,
			env:     combinedEnvs,
			workDir: workDir,
			shell:   shell,
			cmd:     cmd.Cmd,
			tty:     cmd.TTY,
		}

		out, stdout, stderr, err := RunTableCmd(t, &wg)

		// Add exit code to dataExit
		var errCode int
		switch err := err.(type) {
		case *ssh.ExitError:
			errCode = err.ExitStatus()
		case *exec.ExitError:
			errCode = err.ExitCode()
		}

		// TODO: Are mutex needed
		// dataMutex.Lock()
		// out, err := io.ReadAll(client.Stderr())
		// dataMutex.Unlock()
		if err != nil {
			data.Rows[t.rIndex].Columns[t.cIndex] = fmt.Sprintf("%s\n%s", out, err.Error())
		} else {
			data.Rows[t.rIndex].Columns[t.cIndex] = strings.TrimSuffix(out, "\n")
		}

		dataExit.Rows[rIndex].Columns[j+1] = fmt.Sprint(errCode)

		if task.Tasks[j].Register != "" {
			register[task.Tasks[j].Register] = strings.TrimSuffix(out, "\n")
			// strings.TrimSuffix(string(out), "\n"))
			register[task.Tasks[j].Register+"_stdout"] = stdout
			register[task.Tasks[j].Register+"_stderr"] = stderr
			register[task.Tasks[j].Register+"_rc"] = dataExit.Rows[rIndex].Columns[j+1]
			if err != nil {
				register[task.Tasks[j].Register+"_failed"] = "true"
			} else {
				register[task.Tasks[j].Register+"_failed"] = "false"
			}
			// TODO: Add skipped env variable

			registerEnvs = []string{}
			for k, v := range register {
				envStdout := fmt.Sprintf("%v=%v", k, v)
				registerEnvs = append(registerEnvs, envStdout)
			}
		}

		if !task.Spec.IgnoreErrors && err != nil {
			return err
		}
	}

	wg.Wait()

	return nil
}

func RunTableCmd(t TaskContext, wg *sync.WaitGroup) (string, string, string, error) {
	buf := new(bytes.Buffer)
	bufOut := new(bytes.Buffer)
	bufErr := new(bytes.Buffer)

	if t.dryRun {
		return t.cmd, bufOut.String(), bufErr.String(), nil
	}

	if t.tty {
		return buf.String(), bufOut.String(), bufErr.String(), ExecTTY(t.cmd, t.env)
	}

	err := t.client.Run(t.env, t.workDir, t.shell, t.cmd)
	if err != nil {
		return buf.String(), bufOut.String(), bufErr.String(), err
	}

	// Copy over commands STDOUT.
	var stdoutHandler = func(client Client) {
		defer wg.Done()
		mw := io.MultiWriter(buf, bufOut)
		_, err = io.Copy(mw, client.Stdout())

		if err != nil && err != io.EOF {
			fmt.Fprintf(os.Stderr, "%v", err)
		}
	}
	wg.Add(1)
	go stdoutHandler(t.client)

	// Copy over tasks's STDERR.
	var stderrHandler = func(client Client) {
		defer wg.Done()
		mw := io.MultiWriter(buf, bufErr)
		_, err = io.Copy(mw, client.Stderr())
		if err != nil && err != io.EOF {
			fmt.Fprintf(os.Stderr, "%v", err)
		}
	}
	wg.Add(1)
	go stderrHandler(t.client)

	wg.Wait()

	if err := t.client.Wait(); err != nil {
		return buf.String(), bufOut.String(), bufErr.String(), err
	}

	return buf.String(), bufOut.String(), bufErr.String(), nil
}
